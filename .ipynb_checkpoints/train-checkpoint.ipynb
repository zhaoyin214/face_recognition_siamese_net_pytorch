{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from configs.config import config\n",
    "from nets.siamese_net import SiameseNet, ContrastDataset, ContrastLoss\n",
    "from utils.utils import plot_history, imshow\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 训练数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集：CASIA-WebFace\n",
    "\n",
    "验证集：ORL-Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: ImageFolder(root=config[x + \"_set_root\"],\n",
    "                                 transform=None)\n",
    "                  for x in [\"train\", \"val\"]}\n",
    "\n",
    "dataset_size = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = image_datasets[\"train\"].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train identities: 40\n",
      "number of train faces: 400\n",
      "number of val identities: 400\n",
      "number of val faces: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"number of train identities: {}\".format(len(image_datasets[\"train\"].classes)))\n",
    "print(\"number of train faces: {}\".format(dataset_size[\"train\"]))\n",
    "print(\"number of val identities: {}\".format(dataset_size[\"val\"]))\n",
    "print(\"number of val faces: {}\".format(len(image_datasets[\"val\"].classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 对比数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.Resize(100),\n",
    "        transforms.RandomResizedCrop(90),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(100),\n",
    "        transforms.CenterCrop(90),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "contrast_datasets = {x: ContrastDataset(img_folder_dataset=image_datasets[x],\n",
    "                                        transform=data_transforms[x])\n",
    "                     for x in [\"train\", \"val\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {x: torch.utils.data.DataLoader(dataset=contrast_datasets[x],\n",
    "                                               batch_size=config[x + \"_batch_size\"],\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=0)\n",
    "                for x in [\"train\", \"val\"]}\n",
    "dataset_size = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 孪生网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNet(\n",
       "  (res_net_50): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (down_sample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (down_sample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (down_sample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (down_sample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# network\n",
    "net = SiameseNet(dim_embedding=config[\"dim_embedding\"],\n",
    "                 is_rgb=config[\"is_rgb\"])\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 对比损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = ContrastLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# Decay LR by a factor of 0.5 every 10 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loaders, criterion, optimizer, scheduler, num_epochs=25,\n",
    "                early_stopping_patience=None,\n",
    "                reduce_lr_on_plateau=None):\n",
    "    \n",
    "    history = dict(epoch=[],\n",
    "                   train_loss=[],\n",
    "                   val_loss=[])\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 0\n",
    "    \n",
    "    if early_stopping_patience is not None:\n",
    "        early_stopping_cnt = 0\n",
    "        \n",
    "    if reduce_lr_on_plateau is not None:\n",
    "        reduce_lr_on_plateau_cnt = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            running_loss = 0\n",
    "            \n",
    "            # progress bar\n",
    "            pbar = tqdm(total=len(data_loaders[phase]),\n",
    "                        desc=phase,\n",
    "                        ascii=True)\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for data in data_loaders[phase]:\n",
    "                img1s = data[0].to(device)\n",
    "                img2s = data[1].to(device)\n",
    "                labels = data[2].to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    embedding1s, embedding2s = model(img1s, img2s)\n",
    "                    loss = criterion(embedding1s, embedding2s, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                # statistics\n",
    "                running_loss += loss.item() * labels.size(0)\n",
    "                pbar.update(1)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            pbar.close()                \n",
    "            \n",
    "            print(\"{} Loss: {:.4f}\".format(\n",
    "                phase, epoch_loss))\n",
    "            \n",
    "            # history\n",
    "            if phase == \"train\":\n",
    "                history[\"epoch\"].append(epoch)\n",
    "                history[\"train_loss\"].append(epoch_loss)\n",
    "            elif phase == \"val\":\n",
    "                history[\"val_loss\"].append(epoch_loss)\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "            # early stopping\n",
    "            if early_stopping_patience is not None:\n",
    "                if phase == \"val\" and epoch_loss < best_loss:\n",
    "                    early_stopping_cnt += 1\n",
    "                elif phase == \"val\" and epoch_loss >= best_loss:\n",
    "                    early_stopping_cnt = 0\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                if early_stopping_cnt >= early_stopping_patience:\n",
    "                    print(\"Early Stopping...\")\n",
    "                    # load best model weights\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model, history\n",
    "                \n",
    "            # reduce lr on plateau\n",
    "            if reduce_lr_on_plateau is not None:\n",
    "                if phase == \"val\" and epoch_loss < best_loss:\n",
    "                    reduce_lr_on_plateau_cnt += 1\n",
    "                elif phase == \"val\" and epoch_loss >= best_loss:\n",
    "                    reduce_lr_on_plateau_cnt = 0\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                if reduce_lr_on_plateau_cnt >= reduce_lr_on_plateau[\"patience\"]:\n",
    "                    reduce_lr_on_plateau_cnt = 0\n",
    "                    print(\"Error Plateau, Reducing the Learning Rate...\")\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group[\"lr\"] *= reduce_lr_on_plateau[\"factor\"]\n",
    "                    print(\"Learning Rate: {}\".format(param_group[\"lr\"]))\n",
    "                    \n",
    "            # best save\n",
    "            if phase == \"val\" and epoch_loss > best_loss:\n",
    "                print(\"Best Save...\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(),\n",
    "                           \"./output/best_model-epoch_{}-val_loss_{:.4f}.pth\".format(\n",
    "                               epoch, epoch_loss))\n",
    "                print(\"./output/best_model-epoch_{}-val_loss_{:.4f}.pth\".format(\n",
    "                    epoch, epoch_loss))\n",
    "                \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best val Acc: {:4f}\".format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:09<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 9.8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2291\n",
      "Best Save...\n",
      "./output/best_model-epoch_0-val_loss_1.2291.pth\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 1/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.9473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1428\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 2/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.2676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1120\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 3/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0528\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 4/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0765\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 5/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1075\n",
      "Error Plateau, Reducing the Learning Rate...\n",
      "Learning Rate: 0.0002\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 6/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0733\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 7/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1014\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 8/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0896\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 9/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0770\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 10/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0566\n",
      "Error Plateau, Reducing the Learning Rate...\n",
      "Learning Rate: 2e-05\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 11/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0610\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 12/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0725\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 13/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0610\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 14/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0444\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch 15/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|#############################################################################| 7/7 [00:04<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|###############################################################################| 1/1 [00:01<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0795\n",
      "Early Stopping...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net, history = train_model(model=net,\n",
    "                           data_loaders=data_loaders,\n",
    "                           criterion=criterion,\n",
    "                           optimizer=optimizer,\n",
    "                           scheduler=exp_lr_scheduler,\n",
    "                           num_epochs=config[\"train_epochs\"],\n",
    "                           early_stopping_patience=config[\"early_stopping_patience\"],\n",
    "                           reduce_lr_on_plateau = config[\"reduce_lr_on_plateau\"])\n",
    "\n",
    "with open(\"./output/history.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(history, fw)\n",
    "    \n",
    "plot_history(history, \"./output/history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
